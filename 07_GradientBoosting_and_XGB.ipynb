{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36445b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from hyperopt import fmin, tpe, Trials, STATUS_OK, hp, space_eval\n",
    "from hyperopt.pyll import scope\n",
    "from functools import partial\n",
    "\n",
    "from pickle import dump\n",
    "\n",
    "from scripts.Preprocessing import Preprocessing\n",
    "from scripts.BinaryClassificationTraining import BinaryClassificationTraining\n",
    "\n",
    "from scripts.config import (year_month_train, \n",
    "    input_data_path_train,\n",
    "    seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36b31eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path_save = './local_artifacts_tmp/07_GB_XGB/'\n",
    "year_month = year_month_train\n",
    "input_data_path = input_data_path_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b32d9f2",
   "metadata": {},
   "source": [
    "### MLFlow setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebde894d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/19 12:08:29 INFO mlflow.tracking.fluent: Experiment with name '07 - GB and XGB' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(local_path_save):\n",
    "    os.makedirs(local_path_save)\n",
    "\n",
    "#save all metadata in a sqlite db. Artifacts will be saved on local folder ./mlflow    \n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "\n",
    "# Name of the experiment\n",
    "exp_name = \"07 - GB and XGB\"\n",
    "# set up MlFlow axperiment\n",
    "experiment_id = mlflow.set_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45890c45",
   "metadata": {},
   "source": [
    "## Gradient Boosting (sklearn implementation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c23364",
   "metadata": {},
   "source": [
    "Write here your experiments, using what we have already done in the previous sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6148161",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25ef7058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davideposillipo/Documents/Didattica.nosync/DSR_ML_Fundamentals_2023/scripts/Preprocessing.py:161: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  df['lpep_pickup_datetime_week'] = df['lpep_pickup_datetime'].dt.week\n",
      "/Users/davideposillipo/Documents/Didattica.nosync/DSR_ML_Fundamentals_2023/scripts/Preprocessing.py:161: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  df['lpep_pickup_datetime_week'] = df['lpep_pickup_datetime'].dt.week\n"
     ]
    }
   ],
   "source": [
    "prepr = Preprocessing(input_data_path_train, task_type='classification')\n",
    "X, Y = prepr.read_dataframe(request_tgt=True)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.3, random_state=seed)\n",
    "\n",
    "\n",
    "#preprocessing ohe\n",
    "shapes_pre = (X_train.shape[0], X_test.shape[0])\n",
    "X_train_ohe, ohe, scaler = prepr.preprocess_for_classification(df=X_train, \n",
    "                                                               fit_ohe=True,\n",
    "                                                               perform_scaling=True)\n",
    "X_test_ohe, _, _ = prepr.preprocess_for_classification(df=X_test, \n",
    "                                                    ohe=ohe,\n",
    "                                                    perform_scaling=True,\n",
    "                                                    scaler=scaler)\n",
    "assert shapes_pre == (X_train.shape[0], X_test.shape[0])\n",
    "dump(ohe, open(local_path_save + run_name + '_ohe.pkl', 'wb'))\n",
    "dump(scaler, open(local_path_save + run_name + '_scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11b9519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gradient_boosting_training = BinaryClassificationTraining(\n",
    "    input_data_path,\n",
    "    local_path_save,\n",
    "    year_month,\n",
    "    'gradient_boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a092af7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.04s/trial, best loss: 0.6286334502890578]\n",
      "  0%|                                                                                                                            | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davideposillipo/.pyenv/versions/3.10.9/envs/prova/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:08<00:00,  8.82s/trial, best loss: 0.6807145155974677]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:15<00:00, 15.23s/trial, best loss: 0.6978598173206313]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:21<00:00, 21.10s/trial, best loss: 0.7099068964614647]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:27<00:00, 27.83s/trial, best loss: 0.7168051128569203]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:33<00:00, 33.98s/trial, best loss: 0.7205579876714626]\n"
     ]
    }
   ],
   "source": [
    "for B in np.arange(10,600,100, dtype=int):\n",
    "    \n",
    "    max_evals = 1\n",
    "                   \n",
    "    # Here we can decide which hyperparameters we want to tune\n",
    "    gb_parameters_search = {\n",
    "        'n_estimators': B,\n",
    "        'max_depth': 2\n",
    "    }\n",
    "\n",
    "    gradient_boosting_training.set_hyperparameter_space(gb_parameters_search)\n",
    "                   \n",
    "    trials = Trials()\n",
    "\n",
    "    best_result = fmin(\n",
    "        fn=partial(gradient_boosting_training.objective_gradient_boosting, \n",
    "            X_train=X_train_ohe,\n",
    "            X_test=X_test_ohe,\n",
    "            Y_train=Y_train,\n",
    "            Y_test=Y_test,\n",
    "            run_name=run_name,\n",
    "            threshold=0.89),\n",
    "        space=gradient_boosting_training.hp_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=max_evals,\n",
    "        trials=trials,\n",
    "        rstate=np.random.default_rng(seed)\n",
    "    )\n",
    "\n",
    "    best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7952e295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721dc843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cd519f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f28854fe",
   "metadata": {},
   "source": [
    "## XGB with categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec621add",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'xgb_categorical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364cb4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cat_training = BinaryClassificationTraining(\n",
    "    input_data_path,\n",
    "    local_path_save,\n",
    "    year_month,\n",
    "    'xgb_cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60281d74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prepr = Preprocessing(input_data_path_train, task_type='classification')\n",
    "X, Y = prepr.read_dataframe(request_tgt=True)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.3, random_state=seed)\n",
    "\n",
    "\n",
    "#preprocessing ohe\n",
    "shapes_pre = (X_train.shape[0], X_test.shape[0])\n",
    "X_train_cat, _, scaler = prepr.preprocess_for_classification(df=X_train, \n",
    "                                                               enable_categorical=True, \n",
    "                                                               perform_scaling=True)\n",
    "X_test_cat, _, _ = prepr.preprocess_for_classification(df=X_test, \n",
    "                                                    enable_categorical=True,\n",
    "                                                    perform_scaling=True,\n",
    "                                                    scaler=scaler)\n",
    "assert shapes_pre == (X_train.shape[0], X_test.shape[0])\n",
    "dump(scaler, open(local_path_save + run_name + '_scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a8d945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the baseline\n",
    "\n",
    "xgb_cat_training.calculate_classification_baseline(Y_train=Y_train, \n",
    "                                               Y_test=Y_test, run_name=run_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e9adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_evals = 3\n",
    "\n",
    "# Here we can decide which hyperparameters we want to tune\n",
    "xgboost_cat_parameters_search = {\n",
    "    # https://xgboost-clone.readthedocs.io/en/latest/parameter.html#learning-task-parameters\n",
    "    \"objective\":'binary:logistic',\n",
    "    \"tree_method\": \"hist\",\n",
    "    #\"n_estimators\": scope.int(hp.quniform('n_estimators', 5, 20, 1)),\n",
    "    \"n_estimators\": 100,\n",
    "    \"eval_metric\": \"auc\", \n",
    "    \"max_depth\": hp.choice('max_depth', np.arange(1, 5, dtype=int)), #xgb alllows only int max_depth (max_depth=1.0 will raise an error)\n",
    "    'eta': hp.uniform('eta', 0.5, 2),\n",
    "    #\"colsample_bylevel\": 0.7,# stocastic gb (at each split(level) randomly choose between 70% of features )\n",
    "    'enable_categorical': True, #if categorical data are present (i.e. fetures with pandas type='Category') they are managed, If they are not present and 'enable_categorical=True --> no problem\n",
    "    #\"early_stopping_rounds\": 10,\n",
    "    \"seed\": seed\n",
    "}\n",
    "\n",
    "xgb_cat_training.set_hyperparameter_space(xgboost_cat_parameters_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=partial(xgb_cat_training.objective_xgb, \n",
    "        X_train=X_train_cat,\n",
    "        X_test=X_test_cat,\n",
    "        Y_train=Y_train,\n",
    "        Y_test=Y_test,\n",
    "        save_ohe=False,\n",
    "        run_name=run_name,\n",
    "        threshold=0.5),\n",
    "    space=xgb_cat_training.hp_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=max_evals,\n",
    "    trials=trials,\n",
    "    rstate=np.random.default_rng(seed)\n",
    ")\n",
    "\n",
    "best_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4966f472",
   "metadata": {},
   "source": [
    "## XGB with OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb70197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'xgb_ohe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87bd453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_ohe_training = BinaryClassificationTraining(\n",
    "    input_data_path,\n",
    "    local_path_save,\n",
    "    year_month,\n",
    "    'xgb_ohe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1517859",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davideposillipo/Documents/Didattica.nosync/DSR_ML_Fundamentals_2023/scripts/Preprocessing.py:161: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  df['lpep_pickup_datetime_week'] = df['lpep_pickup_datetime'].dt.week\n",
      "/Users/davideposillipo/Documents/Didattica.nosync/DSR_ML_Fundamentals_2023/scripts/Preprocessing.py:161: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  df['lpep_pickup_datetime_week'] = df['lpep_pickup_datetime'].dt.week\n"
     ]
    }
   ],
   "source": [
    "prepr = Preprocessing(input_data_path_train, task_type='classification')\n",
    "X, Y = prepr.read_dataframe(request_tgt=True)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.3, random_state=seed)\n",
    "\n",
    "\n",
    "#preprocessing ohe\n",
    "shapes_pre = (X_train.shape[0], X_test.shape[0])\n",
    "X_train_ohe, ohe, scaler = prepr.preprocess_for_classification(df=X_train, \n",
    "                                                               fit_ohe=True,\n",
    "                                                               perform_scaling=True)\n",
    "X_test_ohe, _, _ = prepr.preprocess_for_classification(df=X_test, \n",
    "                                                    ohe=ohe,\n",
    "                                                    perform_scaling=True,\n",
    "                                                    scaler=scaler)\n",
    "assert shapes_pre == (X_train.shape[0], X_test.shape[0])\n",
    "dump(ohe, open(local_path_save + run_name + '_ohe.pkl', 'wb'))\n",
    "dump(scaler, open(local_path_save + run_name + '_scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9adee2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davideposillipo/.pyenv/versions/3.10.9/envs/prova/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/davideposillipo/.pyenv/versions/3.10.9/envs/prova/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5, 'status': 'ok'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the baseline\n",
    "\n",
    "xgb_ohe_training.calculate_classification_baseline(Y_train=Y_train, \n",
    "                                               Y_test=Y_test, run_name=run_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7303dfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.32s/trial, best loss: 0.6439432877765205]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.01s/trial, best loss: 0.7100954027952776]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:09<00:00,  9.91s/trial, best loss: 0.7226257571485171]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:13<00:00, 13.76s/trial, best loss: 0.726733113104395]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:18<00:00, 18.43s/trial, best loss: 0.7296594601476045]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:22<00:00, 22.25s/trial, best loss: 0.7313985519144212]\n"
     ]
    }
   ],
   "source": [
    "for B in np.arange(10,600,100, dtype=int):\n",
    "    \n",
    "    max_evals = 1\n",
    "                   \n",
    "    # Here we can decide which hyperparameters we want to tune\n",
    "    xgb_parameters_search = {\n",
    "        'n_estimators': B,\n",
    "        'max_depth': 2\n",
    "    }\n",
    "\n",
    "    xgb_ohe_training.set_hyperparameter_space(xgb_parameters_search)\n",
    "                   \n",
    "    trials = Trials()\n",
    "\n",
    "    best_result = fmin(\n",
    "        fn=partial(xgb_ohe_training.objective_xgb, \n",
    "            X_train=X_train_ohe,\n",
    "            X_test=X_test_ohe,\n",
    "            Y_train=Y_train,\n",
    "            Y_test=Y_test,\n",
    "            run_name=run_name,\n",
    "            threshold=0.89),\n",
    "        space=xgb_ohe_training.hp_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=max_evals,\n",
    "        trials=trials,\n",
    "        rstate=np.random.default_rng(seed)\n",
    "    )\n",
    "\n",
    "    best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bc850f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3bde2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fd29a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29036ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_evals = 3\n",
    "\n",
    "# Here we can decide which hyperparameters we want to tune\n",
    "xgboost_ohe_parameters_search = {\n",
    "    # https://xgboost-clone.readthedocs.io/en/latest/parameter.html#learning-task-parameters\n",
    "    \"objective\":'binary:logistic',\n",
    "    \"tree_method\": \"hist\",\n",
    "    #\"n_estimators\": scope.int(hp.quniform('n_estimators', 5, 20, 1)),\n",
    "    \"n_estimators\": 100,\n",
    "    \"eval_metric\": \"auc\", \n",
    "    \"max_depth\": hp.choice('max_depth', np.arange(1, 5, dtype=int)), #xgb alllows only int max_depth (max_depth=1.0 will raise an error)\n",
    "    'eta': hp.uniform('eta', 0.5, 2),\n",
    "    #\"colsample_bylevel\": 0.7,# stocastic gb (at each split(level) randomly choose between 70% of features )\n",
    "    'enable_categorical': False, #if categorical data are present (i.e. fetures with pandas type='Category') they are managed, If they are not present and 'enable_categorical=True --> no problem\n",
    "    #\"early_stopping_rounds\": 10,\n",
    "    \"seed\": seed\n",
    "}\n",
    "\n",
    "xgb_ohe_training.set_hyperparameter_space(xgboost_ohe_parameters_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead37ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=partial(xgb_ohe_training.objective_xgb, \n",
    "        X_train=X_train_ohe,\n",
    "        X_test=X_test_ohe,\n",
    "        Y_train=Y_train,\n",
    "        Y_test=Y_test,\n",
    "        run_name=run_name,\n",
    "        threshold=0.5),\n",
    "    space=xgb_ohe_training.hp_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=max_evals,\n",
    "    trials=trials,\n",
    "    rstate=np.random.default_rng(seed)\n",
    ")\n",
    "\n",
    "best_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121a66d0",
   "metadata": {},
   "source": [
    "### Learning Curve of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f212ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e21940",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_scorer = make_scorer(roc_auc_score, needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2241c58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = xgboost_ohe_parameters_search.copy()\n",
    "best_hps['eta'] = best_result['eta']\n",
    "best_hps['max_depth'] = best_result['max_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8423f0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a16a9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb_ohe = XGBClassifier(**best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af49db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(estimator=best_xgb_ohe, X=X_train_ohe, y=Y_train,\n",
    "                                                       cv=10, train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                                                     n_jobs=-1,\n",
    "                                                       scoring=roc_auc_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20593d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b787a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training ROC AUC')\n",
    "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, test_mean, color='green', marker='+', markersize=5, linestyle='--', label='Validation ROC AUC')\n",
    "plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Training Data Size')\n",
    "plt.ylabel('Model ROC AUC')\n",
    "plt.grid()\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7998cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920a1eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
